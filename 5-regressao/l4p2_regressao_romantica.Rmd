---
title: "l4p2_regressao_romantica"
author: "devjaynemorais"
date: "8 de julho de 2019"
output: 
  html_notebook:
    theme: lumen
    fig_width: 7
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: inline
---
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(here)
library(lubridate)
library(ggbeeswarm)
library(ggridges)
library(ggplot2)
library(scales)
library(GGally)
library(pscl)
library(broom)
#install.packages("pscl")
library(modelr) # devtools::install_github("hadley/modelr")

theme_set(theme_bw())
```

Jayne Morais
Mestrado 2019.1 (UFCG) - FPCC2

```{r}

dados = read_csv("speed-dating/speed-dating2.csv")

dados = dados %>% mutate(match = ifelse(dec == "yes", 1, 0))
```

Análise exploratória dos dados:

```{r}
dados  %>%
  ggplot(aes(x = dec, fill = dec)) + 
    geom_bar(width=.5) +
    labs(
        title = "Distribuição de Match",
        y = "Quantidade",
        x = "Match" 
      ) + 
  guides(fill=guide_legend("Deu Match?"))


```
É possível observar que há uma quantidade bem menor de match correspondido do que não correspondido.

```{r}
dados %>%
  #na.omit(samerace) %>%
  ggplot(aes(x = like)) +
  geom_histogram(color = "black",
                 fill = "grey",
                 breaks=seq(0, 10, by = 1)) +
  scale_x_continuous(breaks=seq(0, 10, by = 1)) +
  scale_y_continuous(breaks=seq(0, 10000, by = 100)) +
  labs(x= "Quanto p1 gostou de p2 (like)",
       y = "Quantidade")

dados %>%
  mutate(like = cut(like, 5)) %>% 
  ggplot(aes(x = like, fill = dec)) +
  geom_bar(position = "fill") +
  labs(x= "Quanto p1 gostou de p2 (like)",
       y = "Quantidade")
``` 

```{r}
dados %>%
  #na.omit(samerace) %>%
  ggplot(aes(x = intel)) +
  geom_histogram(color = "black",
                 fill = "green",
                 breaks=seq(0, 10, by = 1)) +
  scale_x_continuous(breaks=seq(0, 10, by = 1)) +
  scale_y_continuous(breaks=seq(0, 10000, by = 100)) +
  labs(x= "Quão inteligente p1 achou p2 (intel)",
       y = "Quantidade")


dados %>%
  mutate(intel = cut(intel, 5)) %>% 
  ggplot(aes(x = intel, fill = dec)) +
  geom_bar(position = "fill") +
  labs(x= "Quão inteligente p1 achou p2 (intel)",
       y = "Quantidade (%)")
``` 
```{r}
dados %>%
  #na.omit(samerace) %>%
  ggplot(aes(x = attr)) +
  geom_histogram(color = "black",
                 fill = "pink",
                 breaks=seq(0, 10, by = 1)) +
  scale_x_continuous(breaks=seq(0, 10, by = 1)) +
  scale_y_continuous(breaks=seq(0, 10000, by = 100)) +
  labs(x= "Quão atraente p1 achou p2 (attr)",
       y = "Quantidade")


dados %>%
  mutate(attr = cut(attr, 5)) %>% 
  ggplot(aes(x = attr, fill = dec)) +
  geom_bar(position = "fill") +
  labs(x= "Quão atraente p1 achou p2 (attr)",
       y = "Quantidade (%)")

``` 
```{r}
#dados %>%
  #na.omit(samerace) %>%
 # ggplot(aes(x = prob, fill = dec)) +
  #geom_histogram(
         #        breaks=seq(0, 10, by = 1)) +
  #scale_x_continuous(breaks=seq(0, 10, by = 1)) +
  #scale_y_continuous(breaks=seq(0, 10000, by = 100)) +
  #labs(x= "Quão atraente p1 achou p2 (prob)",
      # y = "Quantidade")

dados %>%
  #na.omit(samerace) %>%
  ggplot(aes(x = prob)) +
  geom_histogram(color = "black",
                 fill = "blue",
                 breaks=seq(0, 10, by = 1)) +
  scale_x_continuous(breaks=seq(0, 10, by = 1)) +
  scale_y_continuous(breaks=seq(0, 10000, by = 100)) +
  labs(x= "Probabilidade de um novo encontro (prob)",
       y = "Quantidade")

dados %>%
  mutate(prob = cut(prob, 5)) %>% 
  ggplot(aes(x = prob, fill = dec)) +
  geom_bar(position = "fill") +
  labs(x= "Probabilidade de um novo encontro (prob)",
       y = "Quantidade (%)")


``` 

```{r}
dados %>%
  #na.omit(prob) %>%
  ggplot(aes(x = int_corr)) +
  geom_histogram(color = "black",
                 fill = "yellow") +
  #scale_x_continuous(breaks=seq(0, 10, by = 1)) +
  scale_y_continuous(breaks=seq(0, 10000, by = 100)) +
  labs(x= "Correlação de interesses (int_corr)",
       y = "Quantidade")

dados %>%
  mutate(prob = cut(prob, 5)) %>% 
  ggplot(aes(x = prob, fill = dec)) +
  geom_bar(position = "fill") +
  labs(x= "Correlação de interesses (int_corr)",
       y = "Quantidade (%)")
``` 


```{r}
dados  %>%
  ggplot(aes(y=prob, x=int_corr)) +
  geom_point(alpha = 0.1, position = position_jitter(width = 0.25), color="purple") +
  labs(
    title="C", 
    x= "Correlação entre os interesses entre as pessoas", 
    y= "Probabilidade de um novo encontro"
  ) +
  scale_x_log10() 

```  
  
Para esta análise serão escolhidas as seguintes variáveis:

`prob` : que probabiliade p1 acha que p2 tem de querer se encontrar novamente com p- (escala 1-10)
`int_corr` : correlação entre os interesses de p1 e p2
`like` : no geral, quanto p1 gostou de p2?
`intel` : quão inteligente p1 achou p2
`attr` : quão atraente p1 achou p2


```{r}

#dados = dados %>% augment(type.predict = "response")

bm <- glm(match ~ int_corr + prob + like + intel + attr,
      data = dados,  
      family = "binomial")


tidy(bm, conf.int = TRUE)
tidy(bm, conf.int = TRUE, exponentiate = TRUE)

glance(bm)
pR2(bm)
``` 
Com 95% de confiança.

```{r}
tidy(bm, conf.int = TRUE, conf.level = 0.95, exponentiate = TRUE) %>%
  filter(term != "(Intercept)") %>%
  ggplot(aes(term, estimate, ymin = conf.low, ymax = conf.high)) +
  geom_bar(stat = "identity", position = position_dodge(0.8), fill="#00b894", alpha=0.5, width=.7) + 
  geom_errorbar(size = 0.8, width= 0.2) +
  geom_point(color = "red", size = 2) +
  geom_hline(yintercept = 1, colour = "darkred") +
  labs(x = "Variáveis Independentes",
       title = "Intervalos - regressão logística",
       y = expression("Coeficientes estimados"))
``` 

A variável dependente no modelo é $p(x)/(1-p(x))$. Caso queiramos observar o efeito de $x$ em $p(x)$, isso é menos óbvio porque a relação entre $x$ e $p(x)$ é não linear: o efeito depende dos valores de $x$. A forma de fazer: 


# Que fatores nos dados têm efeito relevante na chance do casal ter um match? Descreva se os efeitos são positivos ou negativos e sua magnitude. 


### Conclusão

  Na amostra de dados analisada foi utilizada regressão múltipla logística foi utilizada para analisar se a relação entre as variáveis `prob` (a probabiliade p1 acha que p2 tem de querer se encontrar novamente), `int_corr` (a correlação entre os interesses de p1 e p2), `like` (no geral, quanto p1 gostou de p2), `intel` (quão inteligente p1 achou p2), `attr` (quão atraente p1 achou p2) possuem uma associação com o odds de haver match entre dois participantes do encontro. 

  Os resultados da regressão indicam que um modelo com os 5 preditores no formato $\frac{p(y)}{1-p(y)} = 0,0014 + 1,03^{int\_corr} + 1,19^{prob} + 1,91^{like} + 0,81^{intel} + 1,53^{attr}$ explicam 33,86% da variância da variável de resposta medido pelo McFadden, correspondendo a $\frac{1}{3}$. 
  

  Após análise dos resultados obtidos para os valores das estimativas associadas a cada variável independente, implicam que: 
  
  + Como $y = 0,0014*(1,03^{int\_corr})$, aumentar em uma unidade `int_corr`, faz com que o odds de dar match seja multiplicada por 1,19;
    
  + Como $y = 0,0014*(1,19^{prob})$, aumentar em uma unidade `prob`, faz com que o odds de dar match seja multiplicada por 1,03;
    
  + Como $y = 0,0014*(1,91^{like})$, aumentar em uma unidade `like`, faz com que o odds de dar match seja multiplicada por 1,91;
    
  + Como $y = 0,0014*(0,81^{intel})$, aumentar em uma unidade `intel`, faz com que o odds de dar match seja multiplicada por 0,81;
    
  + Como $y = 0,0014*(1,53^{attr})$, aumentar em uma unidade `attr`, faz com que o odds de dar match seja multiplicada por 1,53.

  **Considerações:**
  
  * A variável $int\_corr$, medida como a correlação entre os interesses de p1 e p2, possui uma relação muito pequena e positiva (ou talvez nem possuir, pelo fato do intervalo de confiança incluir o 0), porém não se pode confirmar ou descartar um efeito importante sobre esta última, com o erro b = [0,81; 1.31], IC com 95%;
    
  * A variável $prob$, medida como a probabiliade p1 acha que p2 tem de querer se encontrar novamente, tem uma relação positiva e relevante com o erro b = [1,15; 1,24], IC com 95%;
    
  * A variável $like$, medida como quanto p1 gostou de p2, possui uma relação muito relevante e positivo com o erro b = [1,78; 2,06], IC com 95%;
    
  * A variável $intel$, medida como quão inteligente p1 achou p2, possui uma relação negativa e pouco relevante com o erro b = [0,76; 0,86], IC com 95%. 
    
  * A variável $attr$, medida como quão atraente p1 achou p2, possui uma relação positiva e relevante com o erro b = [1,45; 1,61], IC com 95%.

  O modelo só explica aproximadamente \frac{1}{3}$ (33,86%) da variância do modelo pelo MC Fadden, e consequentemente, é importante analisar o impacto de outras variáveis para medir o odds de dar match entre os participantes. 

  Portanto, na prática, é possível observar que os de acordo com os dados coletados e disponibilizados por professores da Columbia Business School gerados pelo experimento envolvendo 310 jovens americanos, apontam que dentre as variáveis as variáveis `prob` (a probabiliade p1 acha que p2 tem de querer se encontrar novamente), `int_corr` (a correlação entre os interesses de p1 e p2), `like` (no geral, quanto p1 gostou de p2), `intel` (quão inteligente p1 achou p2), `attr` (quão atraente p1 achou p2): a variável `like` aparenta ser o quesito mais relevante entre candidatos, ou seja, o que produz mais efeito sobre o odds de p1 dar match entre p1 e p2. Enquanto que as variáveis `atrr` e `prob` têm um pequeno efeito positivo e a variável `intel` possui um efeito pequeno e negativo. Já em relação a variável `int_corr` (a correlação entre os interesses de p1 e p2) aparenta ter um efeito muito pequeno e positivo, porém não se pode confirmar ou descartar um efeito importante sobre esta última.



